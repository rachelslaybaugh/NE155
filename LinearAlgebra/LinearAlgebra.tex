%--------------------------------------------------------------------
% NE 155 (intro to numerical simulation of radiation transport)
% Linear Algebra Lecture
% Spring 2014

% formatting
\documentclass[12pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\usepackage{setspace}
\onehalfspacing

\setlength{\parindent}{0mm} \setlength{\parskip}{1em}


% packages
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{times}
\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{graphicx} % for graphics files

% Draw figures yourself
\usepackage{tikz} 

% The float package HAS to load before hyperref
\usepackage{float} % for psuedocode formatting
\usepackage{xspace}

% from Denovo methods manual
\usepackage{mathrsfs}
\usepackage[mathcal]{euscript}
\usepackage{color}
\usepackage{array}

\usepackage[pdftex]{hyperref}

\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\macro}{\ensuremath{\Sigma}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}


%--------------------------------------------------------------------
%--------------------------------------------------------------------
\begin{document}
\begin{center}
{\bf NE 155, Class 4 and 5, S14 \\
Types of Equations cont'd + TE + DE \\ January 29 and 31, 2014}
\end{center}

\setlength{\unitlength}{1in}
\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}

%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Vector Review}

A real $n$-dimensional vector $\bar{x}$ is an ordered set of $n$ real numbers that expresses magnitude and direction:
%
\begin{equation}
\bar{x} = (x_1, x_2, \dots, x_n) \nonumber
\end{equation}

\textbf{Properties}:
%
\begin{enumerate}
\item sum: two vectors of the same size give a new vector of that size: $\bar{x} + \bar{y} = (x_1 + y_1, x_2 + y_2, \dots, x_n + y_n)$

\item scalar multiple: $c\bar{x} = (cx_1, cx_2, \dots, cx_n)$

\item Euclidean norm (length): $||\bar{x}|| = (x_1^2 + x_2^2 + \dots + x_n^2)^{1/2}$

\item dot product: takes two equal length vectors and results in a scalar. 

Algebraically, it is the sum of the products of the corresponding entries of the two sequences of numbers: $\bar{x} \cdot \bar{y} = \sum_{i=1}^n a_i b_i = x_1 y_1 + x_2 y_2 + \dots + x_n y_n$

Geometrically, it is the product of the magnitudes of the two vectors and the cosine of the angle between them. $\bar{x} \cdot \bar{y} = ||\bar{x}|| ||\bar{y}|| cos\theta$.

\item $||\bar{x}||^2 = \bar{x} \cdot \bar{x}$

\item distance from $\bar{x}$ to $\bar{y}$: $||\bar{x} - \bar{y}|| = ((x_1 - y_1)^2 + (x_2 - y_2)^2 + \dots + (x_n - y_n)^2)^{1/2}$

\item commutative property: $\bar{x} + \bar{y} = \bar{y} + \bar{x}$

\item associative property: $(\bar{x} + \bar{y}) + \bar{z} = \bar{x} + (\bar{y} + \bar{z})$

\item distributive property: $c(\bar{x} + \bar{y}) = c\bar{x} + c\bar{y}$
\end{enumerate}

%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Matrices}

\begin{align}
    \ve{A} &= [a_{ij}]_{m\times n}   =    \begin{pmatrix}
      a_{11} & a_{12} & \cdots & a_{1j} & \cdots & a_{1n} \\
      a_{21} & a_{22} & \cdots & a_{2j} & \cdots & a_{2n} \\
       \vdots & \vdots & \ddots & \vdots & \vdots   & \vdots \\     
      a_{31} & a_{32} & \cdots & a_{ij} & \cdots & a_{in} \\
      \vdots & \vdots & \vdots & \vdots & \ddots   & \vdots \\
      a_{m1} & a_{m2} & \cdots & a_{mj} & \cdots & a_{mn} \\
    \end{pmatrix} \nonumber   
\end{align} 
%
where $i = 1, \dots, m$ is the row index and $j = 1, \dots, n$ is the column index.

$\ve{A} \in \mathbb{R}^{m \times n}$ is an $m \times n$ real matrix\\
$\ve{A} \in \mathbb{C}^{m \times n}$ is an $m \times n$ complex matrix

\textbf{Properties}:
%
\begin{enumerate}
\item sum: $\ve{A} + \ve{B} = [a_{ij} + b_{ij}]_{m \times n}$

\item scalar multiple: $c\ve{A} = [c a_{ij}]_{m \times n}$

\item multiplication: $\ve{C} = \ve{A}\ve{B}$;

$\ve{A} \in \mathbb{C}^{m \times n}$, and $\ve{B} \in \mathbb{C}^{n \times p}$, and $\ve{C} \in \mathbb{C}^{m \times p}$, then $c_{ij} = \sum_{k=1}^n a_{ik} b_{kj}$

$\ve{A}\ve{B} \neq \ve{B}\ve{A}$

\item commutative property: $\ve{A} + \ve{B} = \ve{B} + \ve{A}$

\item associative property: $(\ve{A} + \ve{B}) + \ve{C} = \ve{A} + (\ve{B} + \ve{C})$

\item distributive property: $c(\ve{A} + \ve{B}) = c\ve{A} + c\ve{B}$

\end{enumerate}


%-------------------------------------------------------------
\subsection{Definitions}

Given $\ve{A} \in \mathbb{C}^{m \times n}$, \ve{A} is
%
\begin{enumerate}
\item Transpose: $\ve{A} \in \mathbb{C}^{m \times n}$, and $\ve{B} \in \mathbb{C}^{n \times m} = \ve{A}^T from$

$b_{	ij} = a_{ji}$ for $i = 1, \dots, n$ and $j = 1, \dots, m$

\item Conjugate Transpose / adjoint, $\ve{A}^H = \bar{\ve{A}^T}$ is the complex conjugate of the transpose. 

\item Inverse: $\ve{AA}^{-1} = \ve{A}^{-1}\ve{A} = \ve{I}$, where $\ve{I}$ is a diagonal matrix containing ones on the diagonal.

If this exists, $\ve{A}$ is non-singular / invertible. If the inverse exists, it is unique.

\item Symmetric if $\ve{A} = \ve{A}^T$

\item Antisymmetric / skew-symmetric if $\ve{A}^H = -\ve{A}$

\item Hermitian / self-adjoint if $\ve{A} = \ve{A}^H$

\item Regular if $\ve{A}^{-1}$ exists

\item Unitary if $\ve{A}\ve{A}^H = \ve{I}$

\item Normal if $\ve{A}\ve{A}^H = \ve{A}^H\ve{A}$
\end{enumerate}


%-------------------------------------------------------------
%-------------------------------------------------------------
\subsection{Equations and Special Matrices}

We often write systems of equations as $\ve{A}\bar{x} = \bar{b}$ from
\begin{align}
&a_{11} x_1 + a_{12} x_2 + \dots + a_{1n} x_n = b_1 \nonumber \\
&\vdots \nonumber \\
&a_{n1} x_1 + a_{n2} x_2 + \dots + a_{nn} x_n = b_n \nonumber
\end{align}

To find $\bar{x}$, we need to find a way to affect $\ve{A}^{-1}\bar{b}$. This can be done many many ways, and the first thing we'll talk about are methods for inverting the matrix.

\begin{itemize}
\item Tridiagonal matrix has entries on only the main, upper, and lower diagonal
\item Lower triangular has entries on the diagonal and below
\item Upper triangular has entries on the diagonal and above 
\item Block Tridagonal has blocks of elements (like sub-matrices) on the diagonal. The blocks may be full or only partially full. The blocks look like $\ve{D}_k = [\ve{D_{ij}}]_k$
\end{itemize}

The inverse of a diagonal is simply: $d_{ii}^{-1} = 1/d_{ii}$, another diagonal matrix

\textbf{Theorem}: The following are equivalent (see Math 54 or a textbook for proof)
%
\begin{enumerate}
\item $\ve{A}$ is regular
\item Rank($\ve{A}$) = n
\item $\ve{A}\bar{x} = 0$ iff $x=0$
\item $\ve{A}\bar{x} = \bar{b}$ is uniquely solveable $\forall \bar{b}$
\item det($\ve{A}) \neq 0$
\end{enumerate}



%-------------------------------------------------------------
\subsection{Minors, Cofactors, Determinants}

Good illustration: http://www.mathsisfun.com/algebra/matrix-inverse-minors-cofactors-adjugate.html

%If $\ve{A}$ is an $m \times n$ matrix and $k$ is an integer such that $0 < k \leq m$ and $k \leq n$ then a \textbf{$k \times k$ minor}, $M_{kk}$ of $\ve{A}$ is the determinant of the $k \times k$ matrix formed by deleting $m-k$ rows and $n-k$ columns. 

For a square matrix, the \textbf{first order minor}, $M_{ij}$ just deletes the $i^{th}$ row and $j^{th}$ column and takes the determinant. E.g.
%
\begin{align}
    \ve{A} &= \begin{pmatrix}
        1 & 4 & 7 \\
        3 & 0 & 5 \\
        -1 & 9 & 11 \\
    \end{pmatrix} 
    \qquad
    &M_{23} = \text{det}\begin{pmatrix}
       1 & 4 \\
       -1 & 9 
    \end{pmatrix}   
    = ((1 \times 9) - (4 \times -1)) = 13 \nonumber
\end{align} 

The corresponding $i,j$ \textbf{cofactor} of $\ve{A}$ is
%
\begin{equation}
C_{ij} = (-1)^{i+j} M_{ij} \nonumber
\end{equation}
%
You can compute minors and cofactors for all of $\ve{A}$. The $n \times n$ matrix containing all of the cofactors is denoted $\ve{C}$ in this context.

Using these terms, the determinant can be defined in terms of the Laplace expansion
%
\begin{equation}
\text{det}(\ve{A}) = \sum_{j=1}^n a_{ij} C_{ij} = \sum_{i=1}^n a_{ij} C_{ij} \nonumber
\end{equation}

For the above matrix, lets look at the laplace expansion along the second column ($j = 2$; sum runs over $i$)
\begin{align}
\text{det}(\ve{A}) &= (-1)^{1+2} a_{12} M_{12} + (-1)^{2+2} a_{22} M_{22} + (-1)^{3+2} a_{32} M_{32} \nonumber \\
%
&= (-1)^{1+2} \cdot 4 \cdot \text{det}\begin{pmatrix}
        3 & 5 \\
        -1 & 11 \\ \end{pmatrix} + (-1)^{2+2} \cdot 0 \cdot \text{det}\begin{pmatrix} 
        1 & 7 \\
        -1 & 11 \\ \end{pmatrix} + (-1)^{3+2} \cdot 9 \cdot \text{det}\begin{pmatrix} 
        1 & 7 \\
        3 & 5 \\\end{pmatrix} \nonumber \\
%
&= -4 \cdot ((3 \cdot 11) - (5 \cdot -1)) + 0 -9 \cdot ((1 \cdot 5) - (7 \cdot 3)) = -8 \nonumber
\end{align}


\textbf{Properties of Determinants}
\begin{itemize}
\item det($\alpha\ve{A}$) = $\alpha^N$ det($\ve{A}$)

\item det($\ve{A}^T$) = det($\ve{A}$)

\item det($\ve{A}^{-1}$) = 1/det($\ve{A}$)

\item det($\ve{AB}$) = det($\ve{A}$)det($\ve{B}$)

\item det($\ve{A}^n$) = [det($\ve{A}$)]$^n$

\item in general, det($\ve{A + B}$) $\neq$ det($\ve{A}$) + det($\ve{B}$) 
\end{itemize}

The inverse of $\ve{A}$ can be obtained from the determinant and cofactor matrix:
%
\begin{equation}
\ve{A}^{-1} = \frac{1}{\text{det}(\ve{A})}\ve{C}^T \nonumber
\end{equation}
%
If the determinant is zero, then the matrix is singular.

A real matrix where $\ve{A}^{-1} = \ve{A}^T$ is called \textbf{orthogonal}


%-------------------------------------------------------------
\section{Norms}
\subsection{Vector Norms}
Given $\bar{x}, \bar{y} \in \mathcal{R}^n$, a vector norm, denoted by $|| \cdot ||$, has the following properties:
%
\begin{enumerate}
\item $||\bar{x}|| > 0$ and $||\bar{x}|| = 0$ iff $\bar{â€¢} = 0$ (positive definite)
\item $||\bar{x} + \bar{y}|| \leq ||\bar{x}|| + ||\bar{y}||$ (triangle inequality)
\item $||\alpha \bar{x}|| = |\alpha| ||\bar{x}||$ (homogeneous)
\end{enumerate}

The p-norm:
%
\begin{equation}
||\bar{x}||_p \equiv (|x_1|^p + |x_2|^p + \dots + |x_n|^p)^{1/p} \qquad p \geq 1 \nonumber
\end{equation}
%
\begin{itemize}
\item $||\bar{x}||_1 \equiv |x_1| + |x_2| + \dots + |x_n|$
\item $||\bar{x}||_2 \equiv (|x_1|^2 + |x_2|^2 + \dots + |x_n|^2)^{1/2}$
\item $||\bar{x}||_{\infty} \equiv \text{max}_{1 \leq i \leq n} |x_1|$
\end{itemize}


%\subsubsection{LU Decomposition}
%We can often decompose $\ve{A}$ into an upper and lower triangular matrix
%%
%\begin{align}
%\ve{A} &= \ve{L}\ve{U} \qquad \text{and then} \nonumber \\
%%
%\text{det}(\ve{A}) &= \text{det}(\ve{L}) \text{det}(\ve{U}) \qquad \text{and} \nonumber \\
%%
%\ve{A}^{-1} &= \ve{U}^{-1}\ve{L}^{-1} \nonumber
%\end{align}



\end{document}