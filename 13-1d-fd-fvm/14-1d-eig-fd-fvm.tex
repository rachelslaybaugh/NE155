\documentclass[12pt, answers]{exam}
%\documentclass[12pt]{exam}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{setspace}
\PassOptionsToPackage{hyphens}{url}
\usepackage{tabu}
\onehalfspacing
\setlength{\parindent}{0mm} \setlength{\parskip}{1em}

% packages
\RequirePackage{amssymb, amsfonts, amsmath, latexsym, verbatim, xspace, setspace}
\RequirePackage{tikz}
% The float package HAS to load before hyperref
\usepackage{float} % for psuedocode formatting
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{times}
\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{graphicx} % for graphics files

% for creating indented blocks
\usepackage{scrextend}
\usepackage{paralist, tabularx}

% from Denovo Methods Manual
\usepackage{mathrsfs}
\usepackage[mathcal]{euscript}
\usepackage{color}
\usepackage{array}

\usepackage[pdftex]{hyperref}
\usepackage[parfill]{parskip}
\usepackage{cancel}

\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\Macro}{\ensuremath{\Sigma}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}
\newcommand{\cc}[1]{\ensuremath{\overline{#1}}}
\newcommand{\ccm}[1]{\ensuremath{\overline{\mathbf{#1}}}}



%--------------------------------------------------------------------
%--------------------------------------------------------------------
\begin{document}
\begin{center}
{\bf NE 155, Topic 14, S21 \\
Finite Difference and Volume Methods for the Eigenvalue form of the DE \\ April 1, 2021}
\end{center}

\setlength{\unitlength}{1in}
\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}

%------------------------------------------
\subsection*{Helmholtz Form}
When we derived the Diffusion Equation, we skipped over the Helmholtz form. I am bringing it up now b/c it can be a convenient way to solve the DE. This approach can also be useful if you need to generate an analytical solution.

In steady state, we can write the diffusion equation this way:
%
\begin{align*}
-\nabla \cdot D(\vec{r})\nabla \phi(\vec{r}) + 
\Sigma_a \phi(\vec{r}) &= Q(\vec{r})\:, \\
%
\text{where }\qquad Q(\vec{r}) &=
\nu \Sigma_f \phi(\vec{r}) +
S(\vec{r})\:,
\end{align*}
%
which can be written as the Helmholtz equation of applied mathematics:
%http://en.wikipedia.org/wiki/Helmholtz_equation
%
\ifprintanswers 
\begin{align*}
\nabla^2 \phi(\vec{r}) - \frac{1}{L^2}\phi(\vec{r}) &= \frac{-Q(\vec{r})}{D}\:, \\
\text{where }\qquad L &\equiv \sqrt{\frac{D}{\Sigma_a}}\:.
\end{align*}
\else
\\ \vspace*{4em}\\
\fi
%
$L$ is called the neutron diffusion length. This is ``how far a neutron diffuses from a source prior to absorption". 

In the Helmholtz formulation, $\phi$ is amplitude and $\frac{1}{L}$ is wave number. 

This formulation is useful because we know how to solve it. We write
\[\phi(\vec{r}) = \phi_H(\vec{r}) + \phi_P(\vec{r}) \:,\]

For example, we often have:
\[\phi_H(\vec{r}) = A\exp\bigl(-\frac{|\vec{r}|}{L}\bigr) + B\exp\bigl(\frac{|\vec{r}|}{L}\bigr) \:.\]

Going through how to solve this analytically in a variety of circumstances, geometries, etc.\ is another class (NE 150/250). 

%------------------------------------------
\subsection*{Criticality Calculations}
\textbf{Recall:}

We also want to think about the details of how to configure a reactor to get it to work the way we want it to. 
We can write our DE in steady state for a nuclear reactor core:
%
\begin{align*}
-\nabla \cdot D\nabla \phi(\vec{r}) + 
\Sigma_a \phi(\vec{r}) &= \nu \Sigma_f \phi(\vec{r})\:, \\
\text{with} \qquad \phi(\tilde{x}_s) &= 0\:.
\end{align*}
%
Unless we have the proper combination of core composition ($\Sigma_a$, $\Sigma_f$, $D$) and geometry ($\vec{r}$ ,$\vec{r}_s$) details, there is \underline{no} general solution. 

To deal with this, we introduce a parameter $k$ into the equation:
%
\begin{equation}
-\nabla \cdot D\nabla \phi(\vec{r}) + 
\Sigma_a \phi(\vec{r}) = \frac{1}{k}\nu \Sigma_f \phi(\vec{r})\:. \nonumber
\end{equation}
%
Then, for any value of $k$ we assert that there is always a solution. We use an iterative process to find the condition when $k=1$, called ``critical''.

%A reactor is called \textbf{``critical''} if the chain reaction is self-sustaining and time-independent. Another way to think of the addition of $k$ is to assume $\nu$ can be adjusted to obtain a time-independent solution by replacing it with $\frac{\nu}{k}$, where $k$ is the parameter expressing the deviation from critical. 
%
%This substitution changes the transport equation into an \textbf{eigenvalue problem.} A spectrum of eigenvalues can be found, but at \textbf{long times only the non-negative solution corresponding to the largest real eigenvalue will dominate}, and that's $k$. 
%
%$k$ can also be thought of as the asymptotic ratio of the number of neutrons in one generation to the number in the next.

%--------------------------------------------------------------------
\section*{Finite Difference Method, Eigenvalue Problem}

We can extend all of the finite difference and finite volume methods we just learned to the eigenvalue problem case, which is another layer of complication. 

Now instead of a fixed source, we have an eigenvalue problem
\[-\frac{d}{dx}D(x)\frac{d \phi(x)}{dx} + \Sigma_a(x) \phi(x) = \frac{1}{k}\nu \Sigma_f(x) \phi(x) \]
%
\begin{figure}[h!]
\begin{center}
\includegraphics[height=1in]{FVM-fig}
\end{center}
\end{figure}
%
Let's again have a reflecting condition at the centerline ($x_0 = 0$) and vacuum on the right ($x_n = a$):
\begin{align}
\frac{d}{dx}\phi(x) \big|_{x=0} &= 0 \qquad \text{zero net current,} \nonumber\\
\phi(\tilde{a}) &= 0 \qquad \tilde{a} = a + 2D\:. \nonumber
\end{align}
%
We again have a spatial mesh:
%
\begin{center}
\begin{tikzpicture}
\draw (-.25,0)--(1.25,0);
\draw[dotted] (1.25,0)--(2.75,0);
\draw (2.75,0)--(5.25,0);
\draw[dotted] (5.25,0)--(6.75,0);
\draw (6.75,0)--(8.25,0);
%\draw (4,0)--(5.25,0);
\draw (0,-.25)--(0,.25);
\draw (1,-.25)--(1,.25);
%\draw (2,-.25)--(2,.25);
\draw (3,-.25)--(3,.25);
\draw (4,-.25)--(4,.25);
\draw (5,-.25)--(5,.25);
\draw (7,-.25)--(7,.25);
\draw (8,-.25)--(8,.25);
\node[below] at (0,-.25) {$x_0$};
\node[below] at (1,-.25) {$x_1$};
\node[below] at (3,-.25) {$x_{i-1}$};
\node[below] at (4,-.25) {$x_i$};
\node[below] at (5,-.25) {$x_{i+1}$};
\node[below] at (7,-.25) {$x_{n-1}$};
\node[below] at (8,-.25) {$x_n$};
\node[above] at (0.5, 0.5) {$h_1$};
\node[above] at (3.5, 0.5) {$h_i$};
\end{tikzpicture}
\end{center}
%
and in this configuration $x_0 = 0$, $x_n = a$, and $h_i$ is the mesh spacing. There are $n+1$ points and $n$ mesh cells.

Material discontinuities will coincide with the cell \textit{edges}, $x_i$. Thus, we can assume that the cross sections and the diffusion coefficient are constant in each cell.
%
%\begin{align}
%D(x) &= D_i \qquad \text{for } x_{i-1} \leq x \leq x_i \:,\nonumber \\
%\Sigma_{a}(x) &= \Sigma_{a,i} \qquad \text{for } x_{i-1} \leq x \leq x_i \:, \nonumber \\
%\nu\Sigma_f(x) &= \nu\Sigma_{f,i}\;, \quad \text{for } x_{i-1} \leq x \leq x_i\:, \nonumber \\
%h_i &\equiv x_i - x_{i-1} \:.\nonumber 
%\end{align}
%
The unknown values are again defined at the mesh or cell \textit{edges}, e.g.\ $\phi(x_i) = \phi_i$.

We derive the equations just like we did in the fixed source case, but now instead of $S_i$ we have $\nu \Sigma_{f,i}$ on the rhs and a $1/k$ in multiplying the rhs vector.

\ifprintanswers
\begin{align}
\frac{\phi_{i+1} - 2\phi_i + \phi_{i-1}}{h_i^2} - \frac{1}{L_i^2}\phi_i = -\frac{1}{k}\frac{\nu\Sigma_{f,i}}{D_i}\phi_i \qquad i &= 1, 2, \dots, n-1 \:,\nonumber \\
%
-\phi_{i-1} + \bigl(2 + \frac{h_i^2}{L_i^2}\bigr)\phi_i - \phi_{i+1} = \frac{1}{k} h_i^2 \frac{\nu\Sigma_{f,i}}{D_i}\phi_i \qquad i &= 1, 2, \dots, n-1\: \text{ or,} \nonumber\\
%
\nonumber \\
\frac{-D_i}{h_i^2}\phi_{i-1} + \biggl(\frac{2D_i}{h_i^2} + \Sigma_{a,i} \biggr)\phi_i - \frac{D_i}{h_i^2}\phi_{i+1} = \frac{1}{k} \nu\Sigma_{f,i}\phi_i \qquad i &= 1, \dots, n-1 \:.\nonumber 
\end{align}
\else
\vspace*{10em}
\fi

With this formulation we still have the problem that our unknown is defined the cell edges and if the properties in neighboring cells differ we will have discontinuities. To be able to handle \textit{material discontinuities} we're going to do our volume integration again.


%-----------------------------------------------------
%-----------------------------------------------------
\section*{Finite Volume Method}

Like last time, we will integrate the flux and source values across neighboring half-cells.
%
\begin{figure}[h!]
\includegraphics[height=2.5in]{FVM-eig-fig}
\end{figure}

We again assume the cross section and diffusion coefficient are constant in each cell; for $i=1, \dots, n$: 
\begin{align}
D(x) &= D_i\;, \qquad x_{i-1} \leq x \leq x_i \nonumber \\
\Sigma_a(x) &= \Sigma_{a,i}\;, \qquad x_{i-1} \leq x \leq x_i \nonumber \\
\nu\Sigma_f(x) &= \nu\Sigma_{f,i}\;, \quad x_{i-1} \leq x \leq x_i \nonumber \\
h_i &\equiv x_{i} - x_{i-1} \:.\nonumber 
\end{align}
%
We also still assume that the fluxes are constant over the interval centered around $x_i$; for $i=0, \dots, n$:
%
\begin{align}
\phi(x) &= \phi_i \qquad \text{for } \bigl(x_i - \frac{h_i}{2}\bigr) \leq x \leq \bigl(x_i + \frac{h_{i+1}}{2}\bigr)\:. \nonumber %\\
%S(x) &= S_i \qquad \text{for } \bigl(x_i - \frac{h_i}{2}\bigr) \leq x \leq \bigl(x_i + \frac{h_{i+1}}{2}\bigr) \nonumber 
\end{align}

Now, we integrate the differential equation over each cell, $\bigl(x_i - \frac{h_i}{2}\bigr) \leq x \leq \bigl(x_i + \frac{h_{i+1}}{2}\bigr)$:
%
\[\int_{(x_i - \frac{h_i}{2})}^{(x_i + \frac{h_{i+1}}{2})} \biggl(  -\frac{d}{dx}D(x)\frac{d \phi(x)}{dx}\biggr) dx 
+ \int_{(x_i - \frac{h_i}{2})}^{(x_i + \frac{h_{i+1}}{2})} \Sigma_a(x) \phi(x) dx 
= \int_{(x_i - \frac{h_i}{2})}^{(x_i + \frac{h_{i+1}}{2})} \frac{1}{k}\nu \Sigma_f(x) \phi(x) dx\]
%
We'll only add the term we didn't do before:
%
\ifprintanswers
\begin{align}
\int_{(x_i - \frac{h_i}{2})}^{(x_i + \frac{h_{i+1}}{2})} \frac{1}{k}\nu \Sigma_f(x)\phi(x) dx &= 
%
\int_{(x_i - \frac{h_i}{2})}^{(x_i)} \frac{1}{k}\nu \Sigma_f(x) \phi(x) dx + \int_{(x_i)}^{(x_i + \frac{h_{i+1}}{2})} \frac{1}{k}\nu \Sigma_f(x) \phi(x) dx \nonumber\\
%
&\nonumber \\
&= \frac{1}{k} \biggl(\frac{\nu\Sigma_{f,i}h_i + \nu\Sigma_{f,i+1}h_{i+1}}{2} \biggr)\phi_i \:.\nonumber 
\end{align}
\else
\\ \vspace*{4em}
\fi

Collecting all of the terms:
%
\begin{equation}
-D_{i+1}\biggl(\frac{\phi_{i+1} - \phi_i}{h_{i+1}}\biggr) + D_{i}\biggl(\frac{\phi_{i} - \phi_{i-1}}{h_{i}}\biggr) + \biggl(\frac{\Sigma_{a,i}h_i + \Sigma_{a,i+1}h_{i+1}}{2} \biggr)\phi_i =   \frac{1}{k} \biggl(\frac{\nu\Sigma_{f,i}h_i + \nu\Sigma_{f,i+1}h_{i+1}}{2} \biggr)\phi_i \:.\nonumber
\end{equation}

To express this in matrix form we'll use the same abbreviations as last time, and add one for the fission term (where we've divided through by $h_{ii}$ to get the x-sec terms):
\begin{align}
%h_{ii} &= \frac{h_i + h_{i+1}}{2} \nonumber \\
%%
%\Sigma_{a,ii} &= \frac{\Sigma_{a,i}h_i + \Sigma_{a,i+1}h_{i+1}}{h_i + h_{i+1}} \nonumber \\
\nu\Sigma_{f,ii} &= \frac{\nu\Sigma_{f,i}h_i + \nu\Sigma_{f,i+1}h_{i+1}}{h_i + h_{i+1}} \:.\nonumber
\end{align}
%
Then
%
\[a_{i,i-1} \phi_{i-1} + a_{i,i}\phi_i + a_{i, i+1} \phi_{i+1} = \frac{1}{k}\nu\Sigma_{f,ii} \phi_i \qquad \text{for } i = 1, 2, \dots, n-1\:,\]
%
where the $a$s have the same value as last time. (Only the rhs is new.)
%
%\begin{align}
%a_{i,i-1} &= \frac{-D_i}{h_i h_{ii}}\:, \nonumber \\
%a_{i,i} &= \frac{D_i}{h_i h_{ii}} + \frac{D_{i+1}}{h_{i+1} h_{ii}} +\Sigma_{a,ii}\:, \nonumber \\
%a_{i,i+1} &= \frac{-D_{i+1}}{h_{i+1} h_{ii}}:.\nonumber
%\end{align}

We again have a set of $n-1$ linear algebraic equations with $n+1$ unknowns. We will use the boundary conditions to get the rest of the information that we need.


%-------------------------------------------------------
\subsection*{Boundary Conditions}

Again assume $x_n = \tilde{a}$, then the \textbf{vacuum condition} becomes
\[\phi_n = 0\]
and the last equation for $i=n-1$ becomes
\ifprintanswers
\[a_{n-1,n-2} \phi_{n-2} + a_{n-1,n-1}\phi_{n-1} + 0 = \frac{1}{k}\nu\Sigma_{f,(n-1,n-1)} \phi_{n-1}\]
\else
\\ \vspace*{2em}
\fi

To include the \textbf{reflecting} or zero current condition we integrate over $[0, h_{1}/2]$.
%
\begin{figure}[h!]
\includegraphics[height=2in]{ReflectingBC-eig}
\end{figure}
%
\begin{align}
\int_{0}^{\frac{h_{1}}{2}} \biggl(-\frac{d}{dx}D(x)\frac{d \phi(x)}{dx}\biggr) dx &+ \int_{0}^{\frac{h_{1}}{2}} \Sigma_a(x) \phi(x) dx = \int_{0}^{\frac{h_{1}}{2}} \frac{1}{k}\nu \Sigma_f(x) \phi(x) dx \:. \nonumber %\\
%
%-D(x)\frac{d \phi(x)}{dx}\big|_{\frac{h_{1}}{2}} &+ D(x)\frac{d \phi(x)}{dx}\big|_{0} + \Sigma_{a,1}\phi_0 \frac{h_1}{2} = \frac{1}{k}\nu\Sigma_{f,1} \phi_0 \frac{h_1}{2} \nonumber 
\end{align}
%
We perform the integration and can apply the boundary condition $\frac{d \phi(x)}{dx}\big|_{0} = 0$ just like last time, 
%\[-D(x)\frac{d \phi(x)}{dx}\big|_{\frac{h_{1}}{2}} + \Sigma_{a,1}\phi_0 \frac{h_1}{2} = \frac{1}{k}\nu\Sigma_{f,1} \phi_0 \frac{h_1}{2}\]
%%
%Recall that
%\[-D(x)\frac{d \phi(x)}{dx}\big|_{\frac{h_{1}}{2}} \cong -D_{1}\biggl(\frac{\phi_{1} - \phi_0}{h_{1}}\biggr) \]
%
and the first equation ($i=0$) becomes
\[a_{00}^*\phi_0 + a_{01}^* \phi_1 = \frac{1}{k}\nu\Sigma_{f,1} \phi_0 \:,\]
%
where we redefine the $a^*$s to be the same as last time as well.%to be (I've added the * to indicate that these have different definitions than the rest of the terms.)
%
%\begin{align}
%a_{00}^* &= \frac{2D_1}{h_1^2} + \Sigma_{a,1} \nonumber \\
%a_{01}^* &= -\frac{2D_1}{h_1^2} \nonumber 
%\end{align}

We now have $n$ equations and $n$ unknowns, but we formulate it a bit differently: 
\[\ve{A}\vec{\phi} = \frac{1}{k}\ve{F}\vec{\phi}\:,\]
where:
\begin{align}
%\ve{A} &= \begin{pmatrix}
%a_{00}^* & a_{01}^* & 0      & 0 & \cdots & 0 \\
%a_{10}   & a_{11}   & a_{12} & 0 & \cdots & 0 \\
%0        & a_{21}   & a_{22}   & a_{21} &  & \vdots \\
%\vdots        &    & \ddots  & \ddots & \ddots & \vdots \\
%0 & \cdots & 0 & a_{n-3,n-3}   & a_{n-2,n-2} & a_{n-2,n-1} \\
%0        & \cdots   & 0   & 0 & a_{n-1,n-2} & a_{n-1,n-1} 
%\end{pmatrix} \nonumber \\
%%
%\vec{\phi} &= \begin{pmatrix}\phi_0 \\ \phi_1 \\ \phi_2 \\ \vdots \\ \phi_{n-2} \\ \phi_{n-1} \end{pmatrix} \:, \qquad
%
\ve{F} = \begin{pmatrix}
\nu\Sigma_{f,1} & 0 & 0 & 0 & \cdots & 0 \\
0   & \nu\Sigma_{f,11} & 0  & 0 & \cdots & 0 \\
0   & 0 & \nu\Sigma_{f,22}  & 0 & \cdots & 0 \\
\vdots  &     & \ddots  & \ddots & \ddots  & \vdots \\
0 & \cdots & 0 & 0 & \nu\Sigma_{f,n-2,n-2} & 0 \\
0        & \cdots & 0 & 0   & 0 & \nu\Sigma_{f,n-1,n-1} 
\end{pmatrix} \:.\nonumber
\end{align}


%----------------------------------------------------------------
%----------------------------------------------------------------
\section*{Solution Methods}

We are only going to talk about iterative solution methods for eigenvalue problems since no one uses direct methods in practice (dealing with directly solving an eigenvalue matrix problem rapidly becomes intractable). We will formulate the problem this way, where $m$ is the eigenvalue or ``outer" iteration index:
%
\ifprintanswers
\[ \ve{A} \vec{\phi}^{(m+1)} = \frac{1}{k^{(m)}}\ve{F}\vec{\phi^{(m)}}\]
\else
\\ \vspace*{3em}
\fi

There are a variety of ways you can choose to determine convergence. We will consider these convergence criteria:
\begin{align}
\bigg|\frac{k^{(m)} - k^{(m-1)}}{k^{(m)}}\bigg| &< \epsilon_1 \:, \nonumber \\
\bigg|\frac{\phi_i^{(m)} - \phi_i^{(m-1)}}{\phi_i^{(m)}}\bigg| &< \epsilon_2 \qquad \forall i\:. \nonumber
\end{align}
%
Where $\epsilon_1$ is the eigenvalue convergence criterion (often $1 \times 10^{-4}$ or smaller), and $\epsilon_2$ is the flux error criterion (often $1 \times 10^{-3}$ or smaller).

\subsection*{Finding $k$}

But wait, that iterative method was only telling us how to update $\vec{\phi}$. How do we get new iterates for $k$? To sort that out, we're going to think about the physical interpretation of $k$.

The multiplication factor, $k$, can be defined as
\[k = \frac{\text{total production rate}}{\text{total loss rate}}\]
%
We can define two \textbf{operators} (\emph{not matrices}; to get the thing that we solve, we apply our specific discretization methods to turn the operators into matrices) to help us compute this:
%
\begin{align}
A &= -\frac{d}{dx}D(x)\frac{d}{dx} + \Sigma_a(x) \quad \text{is the loss operator,} \nonumber \\
F &= \nu\Sigma_f(x) \qquad \qquad \text{is the production operator.}\nonumber
\end{align}

%Fortunately, the discretized versions of these operators are the matrices that we have $\ve{A}$ and $\ve{F}$, respectively. 
This allows us to write an equation for $k$ as
\ifprintanswers
\[k^{(m+1)} = \frac{\int_0^{\tilde{a}} F \vec{\phi}^{(m+1)}(x)dx}{\int_0^{\tilde{a}} A \vec{\phi}^{(m+1)}(x)dx}\:. \]
\else
\\ \vspace*{3em}
\fi

We can express our iterative method with our operators,
\[ A \vec{\phi}^{(m+1)} = \frac{1}{k^{(m)}}F\vec{\phi^{(m)}}\]
%
and substitute this into our $k$ equation to get
\[k^{(m+1)} = \frac{\int_0^{\tilde{a}} F \vec{\phi}^{(m+1)}(x)dx}{\frac{1}{k^{(m)}}\int_0^{\tilde{a}} F \vec{\phi}^{(m)}(x)dx\:.} \]
%
This idea applies to any discretization strategy. To use the finite difference formulation we've developed, we discretize the operators and this can be expressed as:
\ifprintanswers
\[k^{(m+1)} = k^{(m)}\Biggl(\frac{\nu\Sigma_{f,1} \phi_0^{(m+1)} \frac{h_1}{2} + \sum_{i=1}^{n-1} \nu\Sigma_{f,ii} \phi_i^{(m+1)} \frac{h_{ii}}{2}}
{\nu\Sigma_{f,1} \phi_0^{(m)} \frac{h_1}{2} + \sum_{i=1}^{n-1} \nu\Sigma_{f,ii} \phi_i^{(m)} \frac{h_{ii}}{2}}\Biggr)\:.\]
\else
\\ \vspace*{3em}
\fi


\subsection*{Power Method}

Power Iteration (PI) is an old and straightforward algorithm for finding an eigenvalue/vector pair. 

The basic idea is that any non-zero vector can be written as a linear combination of the eigenvectors of $\ve{B}$ because the eigenvectors are linearly independent, namely $\vec{v}_0 = \gamma_1 \vec{x}_1 + \gamma_2 \vec{x}_2 + \cdots + \gamma_n \vec{x}_n$, where $\vec{x}_{j}$ is the $j$th eigenvector and $\gamma_{j}$ is some constant. This specific expression assumes a non-defective $\ve{B}$, though this assumption is not necessary for the method to work. 

Another fact that is used to understand power iteration is that $\ve{B}^m \vec{x}_i = \lambda_i^m \vec{x}_i$. Thus
%
\begin{equation}
  \ve{B}^m \vec{v}_{0} = \gamma_1 \lambda_1^m \vec{x}_1 + \gamma_2 \lambda_2^m \vec{x}_2 + \cdots + \gamma_n \lambda_n^m \vec{x}_n \:.\nonumber
  \label{eq:Ak}
\end{equation}
%
Since $|\lambda_1| > |\lambda_i|, i \ne 1$, the first term in the expansion will dominate as $m \to \infty$ and $\ve{B}^m \vec{v}_{0}$ therefore becomes an increasingly accurate approximation to $\vec{x}_1$. 

In practice, it is desirable to avoid exponentiating a matrix, so we will use an algorithm that does something else. It is also helpful to normalize $\vec{v}_0$ to avoid possible over or underflow.

We are also quite interested in the \textit{convergence behavior} of PI. After $m$ steps, the iteration vector $\vec{v}$ will be: 
%
\ifprintanswers
\begin{equation}
  \vec{v}_{m} = \bigl( \frac{\lambda_{1}^{m}}{\vec{e}_{1}^{T}\ve{B}^{m}\vec{v}_{0}} \bigr) \bigl(\frac{1}{\lambda_{1}^{m}}\ve{B}^{m}\vec{v}_{0} \bigr) \:' \nonumber
\end{equation}
\else
\\ \vspace*{2em}
\fi

% 
where $\vec{e}_{1}^{T}$ is a vector with 1 in the first entry and zeros elsewhere; it selects the first row of $\ve{B}$ in the multiplication. If $\ve{B}$ has eigenpairs $\{(\vec{x}_{j}, \lambda_{j}), 1 \le j \le n \}$ and $\vec{v}_{0}$ has the expansion $\vec{v}_{0} = \sum_{j=1}^{n} \vec{x}_{j}\gamma_{j}$ then
%
\begin{equation}
  \frac{1}{\lambda_{1}^{m}}\ve{B}^{m}\vec{v}_{0} =  \frac{1}{\lambda_{1}^{m}} \sum_{j=1}^{n} \ve{B}^{m}\vec{x}_{j}\gamma_{j} = \sum_{j=1}^{n} \bigl(\frac{\lambda_{j}}{\lambda_{1}} \bigr)^m \vec{x}_{j} \gamma_{j} \:.
  \label{eq:PIexpand}
\end{equation}
%
\ifprintanswers
From equation \eqref{eq:PIexpand} it can be determined that the error is reduced in each iteration by a factor of $|\frac{\lambda_{2}}{\lambda_{1}}|$, which is called the dominance ratio. If $\lambda_2$ is close to $\lambda_1$, then this ratio will be close to unity and the method will converge very slowly. 

If $\lambda_2$ is far from $\lambda_1$, then convergence will happen much more quickly. Put simply, PI is better suited for problems where $\ve{B}$ has eigenvalues that are well separated.  
\else
\vspace*{8em}
\fi


Power iteration is very attractive because it only requires matrix-vector products and two vectors of storage space. Because of its simplicity and low storage cost, PI has been widely used in the transport community for criticality problems for quite some time.

Despite these beneficial characteristics, many current codes use an acceleration method with PI or have moved away from it altogether because of the slow convergence for many problems of interest. Nevertheless, it is still used in some codes, has historical relevance, and is used in many studies as a base comparison case.


\subsubsection*{Algorithm}

The power method applies in our formulation when $\ve{B} \equiv \ve{A}^{-1}\ve{F}$, $\lambda \equiv k$ and $\vec{x} \equiv \vec{\phi}$. 
%
When we write it this way it is technically \textbf{inverse power iteration} because we're using the inverse of $\ve{A}$ rather than $\ve{A}$ (the theory is the same). Be careful when setting up these solvers about whether you are solving for $k$ or $1/k$ to ensure you get the correct eigenvectors.

Here is an algorithm to implement the power method (note: this is not the most efficient way to do this, but it is likely the clearest).
%
\begin{enumerate}
\item get initial values for $k^{(0)}$ and $\phi^{(0)}$ for $i = 0, \dots, n-1$; normalize $\phi_0 = \phi_0 / ||\phi_0||$

\item compute the elements of $\ve{A}$

\item compute the initial fission source
\[\vec{Q}_{f}^{(0)} = \begin{pmatrix}
Q_{f,0}^{(0)} \\ Q_{f,1}^{(0)} \\ \vdots \\ Q_{f,n-1}^{(0)} \\
\end{pmatrix}\]
%
where $Q_{f,i}^{(0)} = \nu\Sigma_{f,ii}\phi_i^{(0)} \: \text{for } i = 1, \dots, n-1$ and $Q_{f,0}^{(0)} = \nu\Sigma_{f,1}\phi_0^{(0)}$

\item for $m = 1, ...,$ convergence:
\begin{enumerate}
\item solve (using a method like Jacobi or GS)
\[\ve{A} \vec{\phi}^{(m)} = \frac{1}{k^{(m-1)}}\vec{Q}_{f}^{(m-1)}\]

\item compute the next fission source $\:Q_{f,i}^{(m)} = \nu\Sigma_{f,ii}\phi_i^{(m)} \: \text{ for } i = 1, \dots, n-1$ and\\ $Q_{f,0}^{(m)} = \nu\Sigma_{f,1}\phi_0^{(m)}$

\item compute the next eigenvalue:
\[k^{(m)} = k^{(m-1)}\Biggl(\frac{Q_{f,0}^{(m)} \frac{h_1}{2} + \sum_{i=1}^{n-1} Q_{f,i}^{(m)} \frac{h_{ii}}{2}}
{Q_{f,0}^{(m-1)} \frac{h_1}{2} + \sum_{i=1}^{n-1} Q_{f,i}^{(m-1)} \frac{h_{ii}}{2}}\Biggr)\]

\item check for convergence
\begin{align}
\bigg|\frac{k^{(m)} - k^{(m-1)}}{k^{(m)}}\bigg| &< \epsilon_1 \nonumber \\
\bigg|\frac{\phi_i^{(m)} - \phi_i^{(m-1)}}{\phi_i^{(m)}}\bigg| &< \epsilon_2 \nonumber
\end{align}

\end{enumerate}
\end{enumerate}

%--------------------------------------------------------------------
%--------------------------------------------------------------------
%\bibliographystyle{plain}
%\bibliography{LinearSolns} 

\end{document}